{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a3fe2a-349f-4dc5-82e9-4e069061a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Environment variables pointing to user folders\n",
    "from os import environ, path, makedirs\n",
    "from json import load\n",
    "\n",
    "environ.setdefault('HOME_DIR', \"/mlinfn/shared/lamarr/\"+ environ['USERNAME'])\n",
    "environ.setdefault('TRAINING_DATA_FOLDER',\"/j100\")\n",
    "environ.setdefault('MODEL_STORAGE'  ,environ['HOME_DIR']+\"/trained_models\"+environ['TRAINING_DATA_FOLDER'])\n",
    "environ.setdefault('FEATHER_FOLDER' ,environ['HOME_DIR']+\"/lb-trksim-train/notebooks/feather_folder\"+environ['TRAINING_DATA_FOLDER'])\n",
    "environ.setdefault(\"TRAIN_DATA\"     ,environ['FEATHER_FOLDER']+\"/resolution-train\")\n",
    "environ.setdefault(\"VALIDATION_DATA\",environ['FEATHER_FOLDER']+\"/resolution-validation\")\n",
    "\n",
    "environ.setdefault(\"MODEL_VARIANT\",\"\")\n",
    "default_output_model = \"/models/resolution/saved_model.pb\"\n",
    "if environ['MODEL_VARIANT'] != '':\n",
    "    model_path,model_name = path.split(default_output_model)\n",
    "    default_output_model = path.join(model_path,environ['MODEL_VARIANT'], model_name)\n",
    "environ.setdefault('OUTPUT_MODEL',environ['MODEL_STORAGE']+default_output_model)\n",
    "\n",
    "with open(\"Models_definitions.json\") as mdl_file: # definition of variant models\n",
    "    models_def = load(mdl_file)\n",
    "    environ.setdefault('MODEL_DEFINITION',models_def['resolution'].get(environ['MODEL_VARIANT'],\"ResolutionGAN(gen_layers=10,discr_layers=10,ref_layers=10,X_shape=X.shape,y_shape=y.shape)\"))\n",
    "\n",
    "_ = environ.setdefault('NB_EXPORT',\"True\") # whether export notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0373a539-1e7f-4508-a1dc-ed83ddf03ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run construct_models.py # script containing models definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6569db22-c890-4ad3-9fc4-5fd28430b6b5",
   "metadata": {},
   "source": [
    "# Training Resolution model\n",
    "##### Tested on kernel `TensorFow on GPU` as defined in the image `landerlini/lhcbaf:v0p8`\n",
    "\n",
    "This notebook is part of a pipeline. It requires the preprocessing step defined in the \n",
    "[GAN preprocessing notebook](./Preprocessing-GANs.ipynb) and the trained model is \n",
    "validated in the [Resolution-validation](./Resolution-validation.ipynb) notebook.\n",
    "\n",
    "### Environment and libraries\n",
    "As for the other trainings, we are handling the GPU with TensorFlow.\n",
    "To make sure the GPU is found, we print below the system name of the accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0053432e-8516-41f3-9945-4b86bb2ae011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/envs/root/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import dask.dataframe as ddf\n",
    "import os\n",
    "from os import environ\n",
    "\n",
    "## Remove annoying warnings \n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "\n",
    "print (\"GPU:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f16ab9-3e18-4e66-9394-6c002d37ca6e",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The data are loaded with our custom `FeatherReader` helper class, defined in the local module [`feather_io`](./feather_io.py).\n",
    "\n",
    "In this notebook, we are using:\n",
    " * *training data*: to optimize the weights of the network\n",
    " * *validation data*: to evaluate overtraining effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3470d95b-ade6-457f-bc89-66b847980a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feather_io import FeatherReader    \n",
    "\n",
    "train_dataset = FeatherReader(environ.get(\"TRAIN_DATA\", \"resolution-train\")).as_tf_dataset()\n",
    "validation_dataset = FeatherReader(environ.get(\"VALIDATION_DATA\", \"resolution-validation\")).as_tf_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afb5c2-1326-4cc4-960f-927f905da79e",
   "metadata": {},
   "source": [
    "A chunk of data is loaded to ease the construction of the model, for example defining the shapes of the input and output tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772e1c5f-43c1-494f-8dc1-4018dd819049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([352184, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_dataset.batch(1_000_000)))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46254391-2b40-4a76-9917-58eb985c7487",
   "metadata": {},
   "source": [
    "## Definition of the model\n",
    "The GANs used in this module are composed of three different neural networks trained simultaneously, namely:\n",
    " * a *generator* neural network that takes as an input the *condition* (such as the generator-level features) and the *random noise* and formulate predictions for the output\n",
    " * a *discriminator* neural network trained to identify whether a sample was part of the reference dataset or was produced by the generator\n",
    " * a *referee* network that mimics the configuration of the discriminator, is trained with a much larger learning rate.\n",
    " \n",
    "Generator and discrminator are part of the architecture of GANs since [they were proposed in 2014](https://arxiv.org/abs/1406.2661),\n",
    "with the underlying idea that the generator has to be trained to worsen the classification ability of the discriminator.\n",
    "Generator and discriminator are players of a game in which they try to drive the classification loss function towards\n",
    "higher and lower values, respectively. The outcome of the game that we wish to reach an equilibrium between \n",
    "the two players (Nash equilibrium) that forces both players to improve their abilities along the training \n",
    "and results into a generator providing samples with distributions almost indistinguishable from those of the \n",
    "reference sample.\n",
    "\n",
    "Unfortunately, using the loss function of the discriminator as adversarial objective of two neural networks \n",
    "makes it harder to interpret it as metric for the goodness of the trained model.\n",
    "A high value of the loss may be obtained with both an excellent generator evaluated by an excellent discriminator, \n",
    "or by an awful generator evaluated by an awful discriminator.\n",
    "To evaluate the progress of the training and assess the overall quality of the generator, we introduced a third\n",
    "neural network to the game that does not contribute to the training of the generator, but is a spectator providing \n",
    "and independent assessment of the agreement between the generated and the trained sample. We call this the *referee\n",
    "network*. Since it does not provide a feedback to the generator, larger jumps in the parameter space do not cause\n",
    "the training procedure of the generator to derail because of confusing information. Therefore, the learning rate can be larger.\n",
    "A large learning rate is also useful to provide timely updates on the status of the network, identifying quickly \n",
    "the discrepancies between the generated and the reference sample.\n",
    "\n",
    "The referee network was found to provide useful information when comparing the loss on the \n",
    "training and validation datasets. Indeed, we observed the ability of the *discriminator* \n",
    "to learn \"by heart\" some of the outlayers in the reference sample, resulting in a classification\n",
    "that does not generalize to the validation dataset.\n",
    "\n",
    "As for other tasks, we observed that L2 regularization is useful to contrast overtraining.\n",
    "In addition, L2 regularization is expected to contrast sharp boundaries in the classification\n",
    "function that may lead to explosions of the gradient when training the generator.\n",
    "\n",
    "As discussed for the acceptance models, we adopted very deep neural networks with skip connections to \n",
    "achieve decent results with limited effort in hyperparameter optimization. This choice might be reviewed\n",
    "with additional effort on tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a2a5c-514f-4471-bd68-b1dd6ff14362",
   "metadata": {},
   "source": [
    "### Generator architecture\n",
    "The generator takes the input conditions and the random noise as inputs and provides the target features as an output.\n",
    "In formula,\n",
    "$$\n",
    "g: \\mathbb R^{N_I} \\otimes \\mathbb R^{N_R} \\to \\mathbb R^{N_O} \n",
    "$$\n",
    "where $N_I$ and $N_O$ respresent the number of input and output features, respectively; while $N_R$ is the \n",
    "dimension of the random noise\n",
    "\n",
    "The activation function of the last layer is linear to avoid any constraint on the generated features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7e26b0-b8ef-480e-a3b9-cb100b2ccac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator,discriminator,referee = eval(environ[\"MODEL_DEFINITION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff3b5f7-27d9-4cb4-b523-ee399a19e9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 140)          0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          18048       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 128)         0           ['dense[0][0]',                  \n",
      " da)                                                              'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          16512       ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 128)         0           ['tf.__operators__.add[0][0]',   \n",
      " mbda)                                                            'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          16512       ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_1[0][0]', \n",
      " mbda)                                                            'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          16512       ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_2[0][0]', \n",
      " mbda)                                                            'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          16512       ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_3[0][0]', \n",
      " mbda)                                                            'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          16512       ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_4[0][0]', \n",
      " mbda)                                                            'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          16512       ['tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_5[0][0]', \n",
      " mbda)                                                            'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          16512       ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_6[0][0]', \n",
      " mbda)                                                            'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          16512       ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_7[0][0]', \n",
      " mbda)                                                            'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          16512       ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 128)         0           ['tf.__operators__.add_8[0][0]', \n",
      " mbda)                                                            'dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 9)            1161        ['tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 184,329\n",
      "Trainable params: 184,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random = generator.inputs[1]\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57c782-2ae6-40d4-821a-65c8bc26eb2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Discriminator\n",
    "The generator takes as an input the conditions and the target features (either generated or from the reference sample) and provide the probability for the sample of being part of the reference sample.\n",
    "\n",
    "In formula,\n",
    "$$\n",
    "d^{(th)}: \\mathbb R^{N_I} \\otimes \\mathbb R^{N_O} \\to [0, 1] \\subset \\mathbb R.\n",
    "$$\n",
    "\n",
    "Usually, to map the response of a neural network in the interval $[0, 1]$, the sigmoid function is used.\n",
    "At implementation level, we decided to move the evaluation of the sigmoid from the activation of the last layer to the computation of the loss function.\n",
    "This is believed to improve the numerical stability of the computation by avoiding taking the exponential of a logarithm.\n",
    "\n",
    "In practice, our implemented discriminator will be described by\n",
    "$$\n",
    "d^{(impl)}: \\mathbb R^{N_I} \\otimes \\mathbb R^{N_O} \\to \\mathbb R.\n",
    "$$\n",
    "\n",
    "\n",
    "In terms of implemntation, the tensor we are passing as an input to the neural network for each batch is composed as depicted\n",
    "in the following table\n",
    "\n",
    "<table width=300>\n",
    "    <tr><th colspan=2>$X$<th><th>$y$</tr>\n",
    "    <tr><td>Input conditions (gen. level features)<td><b>Reference</b> target features<td><td><b>1</b></tr>\n",
    "    <tr><td>Input conditions (gen. level features)<td><b>Generated</b> target features<td><td><b>0</b></tr>\n",
    "</table>\n",
    "\n",
    "The input conditions are repeated twice, but in the first half of the batch \n",
    "they are completed with the output features of the reference samples and labeld as $1$.\n",
    "In the second half of the batch they are completed with randomly generated features and labeld with $0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b907fb2-489e-4e3d-a8dd-e7902b9c2d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 12)           0           ['input_3[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 9)            0           ['input_4[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 21)           0           ['concatenate_2[0][0]',          \n",
      "                                                                  'concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          2816        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          16512       ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 128)         0           ['dense_12[0][0]',               \n",
      " ambda)                                                           'dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          16512       ['tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 128)         0           ['tf.__operators__.add_10[0][0]',\n",
      " ambda)                                                           'dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 128)          16512       ['tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 128)         0           ['tf.__operators__.add_11[0][0]',\n",
      " ambda)                                                           'dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          16512       ['tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 128)         0           ['tf.__operators__.add_12[0][0]',\n",
      " ambda)                                                           'dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          16512       ['tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 128)         0           ['tf.__operators__.add_13[0][0]',\n",
      " ambda)                                                           'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          16512       ['tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 128)         0           ['tf.__operators__.add_14[0][0]',\n",
      " ambda)                                                           'dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 128)          16512       ['tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 128)         0           ['tf.__operators__.add_15[0][0]',\n",
      " ambda)                                                           'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          16512       ['tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 128)         0           ['tf.__operators__.add_16[0][0]',\n",
      " ambda)                                                           'dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 128)          16512       ['tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 128)         0           ['tf.__operators__.add_17[0][0]',\n",
      " ambda)                                                           'dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          16512       ['tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 128)         0           ['tf.__operators__.add_18[0][0]',\n",
      " ambda)                                                           'dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            129         ['tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 168,065\n",
      "Trainable params: 168,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313516e-dedf-4824-8441-54b75465c9c4",
   "metadata": {},
   "source": [
    "### Referee network\n",
    "The referee network mimics the discriminator network, therefore\n",
    "$$\n",
    "r: \\mathbb R^{N_I} \\otimes \\mathbb R^{N_O} \\to \\mathbb R\n",
    "$$\n",
    "The input tensor is built in the same way as for the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca2fae3-c0c9-4417-b682-ed0dfecc1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 12)           0           ['input_6[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 9)            0           ['input_7[0][0]',                \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 21)           0           ['concatenate_5[0][0]',          \n",
      "                                                                  'concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          2816        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          16512       ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 128)         0           ['dense_24[0][0]',               \n",
      " ambda)                                                           'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          16512       ['tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 128)         0           ['tf.__operators__.add_20[0][0]',\n",
      " ambda)                                                           'dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 128)          16512       ['tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 128)         0           ['tf.__operators__.add_21[0][0]',\n",
      " ambda)                                                           'dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          16512       ['tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 128)         0           ['tf.__operators__.add_22[0][0]',\n",
      " ambda)                                                           'dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 128)          16512       ['tf.__operators__.add_23[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 128)         0           ['tf.__operators__.add_23[0][0]',\n",
      " ambda)                                                           'dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          16512       ['tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 128)         0           ['tf.__operators__.add_24[0][0]',\n",
      " ambda)                                                           'dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 128)          16512       ['tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 128)         0           ['tf.__operators__.add_25[0][0]',\n",
      " ambda)                                                           'dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          16512       ['tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 128)         0           ['tf.__operators__.add_26[0][0]',\n",
      " ambda)                                                           'dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 128)          16512       ['tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 128)         0           ['tf.__operators__.add_27[0][0]',\n",
      " ambda)                                                           'dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          16512       ['tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 128)         0           ['tf.__operators__.add_28[0][0]',\n",
      " ambda)                                                           'dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 1)            129         ['tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 168,065\n",
      "Trainable params: 168,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "referee.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea93963-2169-422f-99df-1bb2eaf8c3a8",
   "metadata": {},
   "source": [
    "### Training step\n",
    "\n",
    "The training step is defined with the lower-level tensorflow API because we need to carefully\n",
    "tune which weights we wish to update based on each evaluation of a loss function.\n",
    "\n",
    "Technically, we are using the tensorflow [GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) \n",
    "to keep track of the gradient while we describe the computation of the loss function.\n",
    "We will have a different tape for each neural network, recording the derivatives of the \n",
    "loss functions with respect to the weights of that particular network.\n",
    "\n",
    "#### Notes on the chosen loss function\n",
    "The loss function for the classification task is clearly a Binary Cross Entropy (BCE).\n",
    "However we adopt two non-default options for its computation:\n",
    " * `from_logit=True`, to improve the numerical stability of the gradient computation, which\n",
    "   is of particular importance for GANs because of the very long training procedure that \n",
    "   may inflate the errors due to many subsequent iterations\n",
    " * `label_smoothing=0.1`, to introduce a penalty against overconfident classification, which \n",
    "   corresponds to the *plateaux* of the sigmoid function, where the gradient is null, providing\n",
    "   no useful information for the generator's training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffcea06f-544e-4bde-82f1-d158d316284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "g_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "d_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "r_optimizer = tf.keras.optimizers.Adam(5e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(dataset):\n",
    "    # Unpack the dataset to retrieve input and output\n",
    "    X, y_ref = dataset\n",
    "    \n",
    "    # Compute the batch size\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    \n",
    "    # Prepares the tensor of labels for the discriminator, based on the batch_size\n",
    "    label_true = tf.concat((tf.ones(batch_size), tf.zeros(batch_size)), axis=0)\n",
    "\n",
    "    # Generate the random noise. Once per batch.\n",
    "    r = tf.random.normal([batch_size, random.shape[1]], 0., 1.)\n",
    "    \n",
    "    # Begins the computation of the loss, tracking the gradient\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape_generator:\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape_discriminator:\n",
    "            # The gradient will be computed with respect to the variables defined here\n",
    "            tape_generator.watch(generator.weights)\n",
    "            tape_discriminator.watch(discriminator.weights)\n",
    "            \n",
    "            # Run the generator\n",
    "            y_gen = generator((X, r))\n",
    "\n",
    "            # Run the discriminator and obtain the logits\n",
    "            label_pred = discriminator((X, y_ref, y_gen))\n",
    "            \n",
    "            # Convert the logits into a loss function\n",
    "            d_loss = compute_loss(label_true, label_pred)\n",
    "            \n",
    "            # Invert the loss function of the discriminator to obtain the loss \n",
    "            # of the generator\n",
    "            g_loss = -d_loss\n",
    "            \n",
    "    # Begins the computation of the loss of the referee network\n",
    "    # Note that it is completely indepenent of the generator training\n",
    "    with tf.GradientTape() as tape_referee:\n",
    "        # Defines the variables\n",
    "        tape_referee.watch(referee.weights)\n",
    "        # Runs the referee discriminator\n",
    "        label_referee = referee((X, y_ref, y_gen))\n",
    "        # Compute the loss of the referee network\n",
    "        r_loss = compute_loss(label_true, label_referee)\n",
    "\n",
    "    # Compute the gradients of the loss of each NN wrt. to its weights\n",
    "    g_vars = generator.weights\n",
    "    d_vars = discriminator.weights\n",
    "    r_vars = referee.weights\n",
    "    \n",
    "    d_grads = tape_discriminator.gradient(d_loss, d_vars)\n",
    "    g_grads = tape_generator.gradient(g_loss, g_vars)\n",
    "    r_grads = tape_referee.gradient(r_loss, r_vars)\n",
    "    \n",
    "    ## Apply the gradients\n",
    "    g_optimizer.apply_gradients(zip(g_grads, g_vars))\n",
    "    d_optimizer.apply_gradients(zip(d_grads, d_vars))\n",
    "    r_optimizer.apply_gradients(zip(r_grads, r_vars))\n",
    "    \n",
    "    ## Return the value of the loss for monitoring purpose\n",
    "    return r_loss\n",
    "\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def test_step(dataset):\n",
    "    X, y_ref = dataset\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    r = tf.random.normal([batch_size, random.shape[1]], 0., 1.)\n",
    "    \n",
    "    y_gen = generator((X, r))\n",
    "\n",
    "    label_pred = referee((X, y_ref, y_gen))\n",
    "    label_true = tf.concat((tf.ones(batch_size), tf.zeros(batch_size)), axis=0)\n",
    "\n",
    "    return compute_loss(label_true, label_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d598c1-add7-4d42-94b2-0f107ce694f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    " * Batch size: 1k\n",
    " * Number of epochs: 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67c18301-3951-47d5-8810-3c6ef411a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (validation) loss: 0.280 (0.298):   3%|▎         | 28/1000 [01:06<38:34,  2.38s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m epoch_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dset \u001b[38;5;129;01min\u001b[39;00m train_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     epoch_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdset\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(epoch_losses))\n\u001b[1;32m     15\u001b[0m validation_loss\u001b[38;5;241m.\u001b[39mappend(test_step(vdst)\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange, tqdm\n",
    "\n",
    "losses = []\n",
    "validation_loss = []\n",
    "\n",
    "vdst = next(iter(validation_dataset.batch(100_000)))\n",
    "\n",
    "progress_bar = trange(1000)\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    epoch_losses = []\n",
    "    for dset in train_dataset.batch(1000):\n",
    "        epoch_losses.append(train_step(dset))\n",
    "    losses.append(np.mean(epoch_losses))\n",
    "    validation_loss.append(test_step(vdst).numpy())\n",
    "    \n",
    "    progress_bar.set_description(f\"Training (validation) loss: {losses[-1]:.3f} ({validation_loss[-1]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c474e7b-ee4c-4200-9796-1ec9158c48ca",
   "metadata": {},
   "source": [
    "The evolution of the loss function as evaluated by the referee network is reported below.\n",
    "A dashed line represent the ideal value of the BCE when evaluated on two identical datasets with an ideal classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f21e7869-88bb-4579-8474-c6e5e70c9ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = {\n",
    "    \"loss\":losses,\n",
    "    \"val_loss\":validation_loss\n",
    "}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses, label=\"Training data\")\n",
    "plt.plot(validation_loss, label=\"Validation data\")\n",
    "plt.plot([0, len(losses)], [np.log(2)]*2, 'k--')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "\n",
    "plt.ylabel(\"Binary crossentropy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9e6f7-7be3-4ab3-8478-aa1a6000ac65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exporting the model\n",
    "The model is exported to the same directory were the preprocessing steps `tX` and `tY` were stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef92cb47-5f65-4a7a-a6d0-cc47f8b1bd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /mlinfn/shared/lamarr/scapelli/trained_models/j100/models/resolution/assets\n"
     ]
    }
   ],
   "source": [
    "from models_utils import GetModelProperties,MakeMD\n",
    "from json import dump\n",
    "\n",
    "base_dir = path.dirname(environ['OUTPUT_MODEL'])\n",
    "makedirs(base_dir,exist_ok=True)\n",
    "generator.save(base_dir)\n",
    "\n",
    "# save model and training information\n",
    "jsonfile = \"model_info.json\"\n",
    "info_path = path.join(base_dir, jsonfile)\n",
    "props = GetModelProperties(generator,history=str(history),optimizer=g_optimizer)\n",
    "\n",
    "with open(info_path,'w') as json_file:\n",
    "    dump(props,json_file)\n",
    "\n",
    "# write model description in MD file\n",
    "MakeMD(props,mdfile=path.join(base_dir, \"model_info.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28318b8-239d-4e00-8a95-b839fcb58b99",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook we discussed the training procedure of the GAN model used to parametrize the resolution.\n",
    "\n",
    "In particular, we discussed\n",
    " * the overall structure of the DNN system;\n",
    " * the architecture of the generator, discriminator and of a referee network we introduced to ease monitoring, debugging an hyperparameter optimization\n",
    " * the procedure for optimizing the weights of the three networks based on three different computations of the gradients\n",
    " * the outcome of the training procedure as visualized by the evolution of the loss of the referee network\n",
    "\n",
    "Finally, we exported the model for deployment and further validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a277c8-a92e-4c36-a8d0-975a17481903",
   "metadata": {},
   "outputs": [],
   "source": [
    "### export notebooks for comparisons\n",
    "if environ.get('NB_EXPORT',\"False\")==\"True\":\n",
    "    from os import system,makedirs\n",
    "    \n",
    "    nb_save  = f\"{environ['HOME_DIR']}/notebooks_exports\"  # export output dir\n",
    "    nb_save  = nb_save+environ['TRAINING_DATA_FOLDER']     # according to train data\n",
    "    if environ['MODEL_VARIANT'] != '':\n",
    "        nb_save  = nb_save+'/'+environ['MODEL_VARIANT']    # according to model variant\n",
    "    makedirs(nb_save,exist_ok=True)                       \n",
    "    \n",
    "    nbs_path = f\"{environ['HOME_DIR']}/lb-trksim-train/notebooks\" # notebooks folder\n",
    "    nb_filename = \"Resolution.ipynb\"                              # notebook name\n",
    "    extensions  = [\"html\"]                                  # export formats\n",
    "    for ext in extensions:\n",
    "        system(\"jupyter nbconvert --log-level=40 --no-input --output-dir {0} --to {1} {2}/{3}\".format(nb_save,ext.upper(),nbs_path,nb_filename))\n",
    "    print(\"Exported {} as {} in {}\".format(nb_filename,','.join(extensions),nb_save))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEP",
   "language": "python",
   "name": "hep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
